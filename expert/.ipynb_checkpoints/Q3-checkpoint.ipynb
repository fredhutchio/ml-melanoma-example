{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is the __expert level__ version of [question 3](../novice/Q3.ipynb) from the novice level and [question 3](../intermediate/Q3.ipynb) from the intermediate level. Previously we focused on the frequency of the different types of lesion diagnosis and finding if there is a statistical difference between lesion types (regarding malignancy). This notebook focuses on clustering those same lesion diagnoses by looking at the images and using K-means. We want to see if the size of the clusters are similar to the frequencies found in the previous question. We do this to answer the following question: Does the clustering of lesion diagnosis align with the frequency chart from the beginner section? \n",
    "\n",
    "# Table of Content\n",
    "\n",
    "1. [Setup](#setup_cell)\n",
    "2. [Data Loading](#loading)\n",
    "3. [Analysis](#analyze)\n",
    "4. [Visualization](#viz_cell)\n",
    "5. [Discussion](#discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import <a id=\"setup_cell\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns # pip install -U seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans\n",
    "from kmeans_pytorch import kmeans, kmeans_predict\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading <a id=\"loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filepaths = glob.glob('../../sample_imgs/*.jp*')\n",
    "seg_filepaths = glob.glob('../../sample_segs/*.png')\n",
    "dsc_filepaths = glob.glob('../../sample_dscs/*')\n",
    "\n",
    "img_filepaths = sorted(img_filepaths)\n",
    "seg_filepaths = sorted(seg_filepaths)\n",
    "dsc_filepaths = sorted(dsc_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more image and description files than segmentation so we have to make sure we only use the files that have images, segmentations and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_file_numbers = [str(i.split(\"_\")[-1].split(\".\")[0]) for i in img_filepaths]\n",
    "seg_file_numbers = [str(seg_filepaths[i].split(\"_\")[2]) for i in range(len(seg_filepaths))]\n",
    "des_file_numbers =  [str(dsc_filepaths[i].split(\"_\")[2]) for i in range(len(dsc_filepaths))]\n",
    "                     \n",
    "all_files = [im_file_numbers, seg_file_numbers, des_file_numbers]\n",
    "\n",
    "total_file_count = np.inf\n",
    "total_files = []\n",
    "for directory in all_files:\n",
    "    if len(directory) < total_file_count:\n",
    "        total_file_count = len(directory)\n",
    "        total_files = directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have to make sure all of the files are in the same order so we're using the same segmentations for the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency_fix(total_files):\n",
    "    s = \"_\"\n",
    "    images = []\n",
    "    segs   = []\n",
    "    dscs   = []\n",
    "    \n",
    "    im = img_filepaths[0].split(\"_\")\n",
    "    j = seg_filepaths[0].split(\"_\")\n",
    "    k = dsc_filepaths[0].split(\"_\")\n",
    "    \n",
    "    for i in total_files:\n",
    "\n",
    "        im_file  =  s.join(im[:2]) + \"_\" + i + \".\" + im[-1].split(\".\")[-1]\n",
    "        seg_file =  s.join(j[:2]) + \"_\" + i + \"_\" + j[-1]\n",
    "        des_file =  s.join(k[:2]) + \"_\" + i\n",
    "        \n",
    "        if isfile(im_file) & isfile(seg_file) & isfile(des_file):\n",
    "            \n",
    "            images.append(im_file)\n",
    "            segs.append(seg_file)\n",
    "            dscs.append(des_file)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return images, segs, dscs\n",
    "\n",
    "fixed_img, fixed_seg, fixed_dsc = consistency_fix(total_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fixed_img)):\n",
    "    \n",
    "    image_number = int(fixed_img[0].split(\"_\")[-1].split(\".\")[0])\n",
    "    segmentation_number = int(fixed_seg[0].split(\"_\")[2])\n",
    "    description_number =  int(fixed_dsc[0].split(\"_\")[2])\n",
    "    if image_number != segmentation_number or image_number != description_number:\n",
    "        print(\"Error in file order\")\n",
    "        break\n",
    "\n",
    "img_filepaths = fixed_img\n",
    "seg_filepaths = fixed_seg\n",
    "dsc_filepaths = fixed_dsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks to make sure each image corresponds to it's segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis <a id=\"analyze\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have to grab all the images, their descriptions and segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "classes = []\n",
    "for i in tqdm(range(len(img_filepaths))): # replace with length of sample_imgs\n",
    "    \n",
    "    # Grab orignal image and segmented version \n",
    "    color =  PIL.Image.open(img_filepaths[i])\n",
    "    segged = PIL.Image.open(seg_filepaths[i])\n",
    "    \n",
    "    json_file = open(dsc_filepaths[i]) \n",
    "    description = json.load(json_file)\n",
    "    try:\n",
    "        diag_class = description[\"meta\"][\"clinical\"]['diagnosis']\n",
    "        if diag_class != None:  \n",
    "            classes.append(diag_class)\n",
    "        else:\n",
    "            classes.append(\"None\")\n",
    "    except KeyError:\n",
    "        continue \n",
    "    # Try using different attributes for your classes\n",
    "    #classes.append(description[\"meta\"][\"clinical\"]['anatom_site_general'])\n",
    "    #classes.append(description[\"meta\"][\"clinical\"]['benign_malignant'])\n",
    "\n",
    "    # Get blank background\n",
    "    np_im = np.zeros((300,400))\n",
    "    backtorgb = cv2.cvtColor(np.float32(np_im),cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    blank_array = backtorgb * 255\n",
    "    blank_array = blank_array.astype(np.uint8)\n",
    "    sam = PIL.Image.fromarray(blank_array)\n",
    "\n",
    "    # Copy original picture on blank background\n",
    "    back_im = sam.copy()\n",
    "    back_im.paste(color, (0, 0), segged)\n",
    "    im_matrix = np.array(back_im)\n",
    "    im_matrix = im_matrix.flatten()\n",
    "    all_images.append(im_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means needs numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.array(all_images)\n",
    "all_images = all_images.astype('float64')\n",
    "total_classes = len(set(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs K-means algorithm <br>\n",
    "K-means boils down to 5 steps: <br>\n",
    "1. Randomly select centroids (centers of each cluster).\n",
    "2. Calculate the distance of all data points to the centroids.\n",
    "3. Assign data points to the closest cluster.\n",
    "4. Find the new centroids of each cluster by taking the mean of all data points in the cluster.\n",
    "5. Repeat steps 2,3 and 4 until all points converge or you reach your max iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn version (no GPU)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=total_classes, max_iter=500)\n",
    "kmeans.fit(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the cluster predictions and all the different classes for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = kmeans.predict(all_images)\n",
    "classes = np.array(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must turn them into np arrays for easier processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diagnosis = classes\n",
    "all_clusters = pred_classes\n",
    "all_diagnosis = np.array(all_diagnosis)\n",
    "all_clusters = np.array(all_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we do a couple of things: <br>\n",
    "1. We look at the number of clusters we have\n",
    "2. Then find classes that have been assigned to that cluster\n",
    "3. We then count the number of times that class has appeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = dict()\n",
    "for cluster in range(total_classes):\n",
    "\n",
    "    mini_dic = dict()\n",
    "    for i in np.unique(classes):\n",
    "        index = np.where(pred_classes == cluster)\n",
    "        #print(index)\n",
    "        mini_dic[i] = list(classes[index]).count(i)\n",
    "\n",
    "    cluster_data[cluster] = mini_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a dictionary of dictionaries, which isn't very easy to visualize. So we are going to turn it into a few lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnosis(cluster, cluster_data, tried_diagnoses):\n",
    "    candidates = list(cluster_data[cluster].keys())\n",
    "    candidate_counts = list(cluster_data[cluster].values())\n",
    "    \n",
    "    if len(tried_diagnoses) != 0:\n",
    "        for diagnosis in tried_diagnoses:\n",
    "            if diagnosis in candidates:\n",
    "                candidate_counts.pop(candidates.index(diagnosis))\n",
    "                candidates.pop(candidates.index(diagnosis))\n",
    "    count = max(candidate_counts)\n",
    "    dominant_diagnosis = candidates[candidate_counts.index(count)]\n",
    "    \n",
    "    return dominant_diagnosis, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, diagnosis_count in list(cluster_data.items()):\n",
    "    different_diagnoses = list(diagnosis_count.keys())\n",
    "    diagnoses_count = list(diagnosis_count.values())\n",
    "    \n",
    "    all_clusters.append([cluster]*len(diagnoses_count))\n",
    "    all_counts.append(diagnoses_count)\n",
    "    \n",
    "    if different_diagnoses not in all_diagnosis:\n",
    "        for diagnosis in different_diagnoses:\n",
    "            all_diagnosis.append(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization <a id=\"viz_cell\"><a/>\n",
    "### It is hard to visualize clustering especially when working with high dimensional data like images. So you might have to get creative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used color to represent the clusters, count to represent the size of the clusters, and the x-axis for the classes. Usually we are not concerned with the exact class labels but in this case we want to know the number of different diagnoses in a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.cm.jet(np.linspace(0,1,total_classes))\n",
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "\n",
    "for cluster in np.unique(all_clusters):\n",
    "\n",
    "    \n",
    "\n",
    "    ax.scatter(list(cluster_data[cluster].keys()), list(cluster_data[cluster].values()), c = colors[cluster], label = \"Cluster \" + str(cluster + 1), s = 100) \n",
    "    \n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Diagnosis\")\n",
    "plt.legend()\n",
    "plt.title(\"Sizes of clusters\")\n",
    "plt.savefig(\"../expert_Q3_cluster.png\")\n",
    "plt.imread(\"../expert_Q3_cluster.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have clustered the images, we need to get the number of the correctly clustered images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = dict()\n",
    "counted_clusters = 0\n",
    "for cluster in range(total_classes):\n",
    "    \n",
    "    while len(cluster_sizes) == counted_clusters:\n",
    "        \n",
    "        found_clusters = list(cluster_sizes.keys())\n",
    "        diagnosis, count = get_diagnosis(cluster, cluster_data, found_clusters)\n",
    "        if diagnosis not in found_clusters:\n",
    "            cluster_sizes[diagnosis] = count\n",
    "        else:\n",
    "            diagnosis, count = get_diagnosis(cluster, cluster_data, found_clusters)\n",
    "            \n",
    "        \n",
    "   \n",
    "    counted_clusters += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the sizes of the cluster we want to see how well they represent the distribution. Here we load the data from question one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = pd.read_csv('../diagnosis_distribution.csv')\n",
    "cluster_sizes =  pd.DataFrame(list(zip(cluster_sizes.keys(), cluster_sizes.values())), columns= [\"Diagnosis\", \"Count\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we simply look at the difference of the two values obtained for each diagnosis and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = dict() \n",
    "for diagnosis in cluster_sizes[\"Diagnosis\"]:\n",
    "    cluster_info = int(cluster_sizes[cluster_sizes[\"Diagnosis\"] == diagnosis][\"Count\"])\n",
    "    d = frequency[frequency[\"Diagnosis\"] == diagnosis][\"Count\"]\n",
    "    try:\n",
    "        frequency_info = int(d)\n",
    "    except TypeError:\n",
    "        frequency_info = 0\n",
    "    difference[diagnosis] = abs(cluster_info - frequency_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.title(\"Cluster Error\")\n",
    "plt.bar(list(difference.keys()), list(difference.values()))\n",
    "plt.savefig(\"../expert_Q3_error.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion <a id=discussion></a>\n",
    "Did KMeans put the diagnoses in the appropriate clusters? <br>\n",
    "Does the amount of diagnoses look similar to the distribution in question 1 for novice? <br>\n",
    "Was the difference large or small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
